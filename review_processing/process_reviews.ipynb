{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../reviews/1429_1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m rev1 = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../reviews/1429_1.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m rev2 = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33m../reviews/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m rev3 = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33m../reviews/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Hackathons\\Amazon HackOn\\Models\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Hackathons\\Amazon HackOn\\Models\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Hackathons\\Amazon HackOn\\Models\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Hackathons\\Amazon HackOn\\Models\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Hackathons\\Amazon HackOn\\Models\\venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../reviews/1429_1.csv'"
     ]
    }
   ],
   "source": [
    "rev1 = pd.read_csv(\"../reviews/1429_1.csv\")\n",
    "rev2 = pd.read_csv(\"../reviews/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products_May19.csv\")\n",
    "rev3 = pd.read_csv(\"../reviews/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common columns across all three dataframes:\n",
      "['asins', 'brand', 'categories', 'id', 'keys', 'manufacturer', 'name', 'reviews.date', 'reviews.dateSeen', 'reviews.doRecommend', 'reviews.id', 'reviews.numHelpful', 'reviews.rating', 'reviews.sourceURLs', 'reviews.text', 'reviews.title', 'reviews.username']\n",
      "\n",
      "Number of common columns: 17\n"
     ]
    }
   ],
   "source": [
    "# print(rev1.columns, rev2.columns, rev3.columns)\n",
    "# Find common columns across all three dataframes using set intersection\n",
    "common_columns = list(set(rev1.columns) & set(rev2.columns) & set(rev3.columns))\n",
    "print(\"Common columns across all three dataframes:\")\n",
    "print(sorted(common_columns))\n",
    "print(f\"\\nNumber of common columns: {len(common_columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rev1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Combine all three dataframes using only the common columns\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m combined_df = pd.concat([\u001b[43mrev1\u001b[49m[common_columns], rev2[common_columns], rev3[common_columns]], \n\u001b[32m      3\u001b[39m                        ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCombined dataframe shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcombined_df.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCombined dataframe columns: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(combined_df.columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'rev1' is not defined"
     ]
    }
   ],
   "source": [
    "# Combine all three dataframes using only the common columns\n",
    "combined_df = pd.concat([rev1[common_columns], rev2[common_columns], rev3[common_columns]], \n",
    "                       ignore_index=True)\n",
    "\n",
    "print(f\"Combined dataframe shape: {combined_df.shape}\")\n",
    "print(f\"Combined dataframe columns: {list(combined_df.columns)}\")\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mcombined_df\u001b[49m.columns.sort_values()\n",
      "\u001b[31mNameError\u001b[39m: name 'combined_df' is not defined"
     ]
    }
   ],
   "source": [
    "combined_df.columns.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m review_df_sementic = \u001b[43mcombined_df\u001b[49m[[\u001b[33m\"\u001b[39m\u001b[33mreviews.title\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mreviews.text\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mreviews.rating\u001b[39m\u001b[33m\"\u001b[39m]]\n\u001b[32m      2\u001b[39m review_df_sementic.sample(\u001b[32m5\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'combined_df' is not defined"
     ]
    }
   ],
   "source": [
    "review_df_sementic = combined_df[[\"reviews.title\", \"reviews.text\", \"reviews.rating\"]]\n",
    "review_df_sementic.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'review_df_sementic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mreview_df_sementic\u001b[49m.isnull().sum()\n\u001b[32m      2\u001b[39m review_df_sementic.dropna(inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      3\u001b[39m review_df_sementic.duplicated().sum()\n",
      "\u001b[31mNameError\u001b[39m: name 'review_df_sementic' is not defined"
     ]
    }
   ],
   "source": [
    "review_df_sementic.isnull().sum()\n",
    "review_df_sementic.dropna(inplace=True)\n",
    "review_df_sementic.duplicated().sum()\n",
    "review_df_sementic.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'review_df_sementic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m review_df_sementic.loc[:, \u001b[33m\"\u001b[39m\u001b[33mrating_semantic\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mreview_df_sementic\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mreviews.rating\u001b[39m\u001b[33m\"\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x > \u001b[32m3\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m -\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x < \u001b[32m3\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'review_df_sementic' is not defined"
     ]
    }
   ],
   "source": [
    "review_df_sementic.loc[:, \"rating_semantic\"] = review_df_sementic[\"reviews.rating\"].apply(lambda x: 1 if x > 3 else -1 if x < 3 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Hackathons\\Amazon HackOn\\Models\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "e:\\Hackathons\\Amazon HackOn\\Models\\venv\\Lib\\site-packages\\transformers\\convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Device set to use cuda:0\n",
      "e:\\Hackathons\\Amazon HackOn\\Models\\venv\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Use the yangheng/deberta-v3-large-absa-v1.1 model with proper tokenizer configuration\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "# Load the model with trust_remote_code=True to handle custom tokenizer\n",
    "model_name = \"yangheng/deberta-v3-base-absa-v1.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "# Create aspect-based sentiment pipeline\n",
    "absa_pipe = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_all_scores=True,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# Function to get sentiment scores using the ABSA model\n",
    "def get_absa_sentiment(text):\n",
    "    try:\n",
    "        result = absa_pipe(text[:512])  # Truncate to avoid token limits\n",
    "        # For ABSA model, we need to check the label mapping\n",
    "        # Usually positive sentiment has higher score\n",
    "        return result[0]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {e}\")\n",
    "        return [{\"label\": \"neutral\", \"score\": 0.5}]\n",
    "\n",
    "# Function to convert ABSA result to binary rating\n",
    "def absa_to_rating(absa_result, threshold=0.5):\n",
    "    # Find the highest scoring label\n",
    "    best_score = max(absa_result, key=lambda x: x['score'])\n",
    "    return 1 if best_score['score'] > threshold else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's exactly what you would expect for a tablet under $100. Very basic. Screen resolution if sub par for what's out today. Speed is questionable but works for our 2 year old. [[{'label': 'Negative', 'score': 0.3285614252090454}, {'label': 'Neutral', 'score': 0.35901209712028503}, {'label': 'Positive', 'score': 0.31242650747299194}]] [{'label': 'Negative', 'score': 0.3285614252090454}, {'label': 'Neutral', 'score': 0.35901209712028503}, {'label': 'Positive', 'score': 0.31242650747299194}]\n",
      "CPU times: total: 219 ms\n",
      "Wall time: 211 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text = review_df_sementic['reviews.text'].sample().to_list()[0]\n",
    "print(text, absa_pipe(text), get_absa_sentiment(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a list of texts and return ratings\n",
    "def get_rating_semantic_batch(text_list):\n",
    "    ratings = []\n",
    "    for text in text_list:\n",
    "        try:\n",
    "            absa_result = get_absa_sentiment(text)\n",
    "            # Convert to -1, 0, 1 rating based on sentiment scores\n",
    "            # Find the highest scoring label by comparing scores directly\n",
    "            max_score = 0\n",
    "            best_label = 'neutral'\n",
    "            for item in absa_result:\n",
    "                if abs(item['score']) > abs(max_score):\n",
    "                    max_score = item['score']\n",
    "                    best_label = item['label']\n",
    "            \n",
    "            \n",
    "            if best_label == 'Positive':\n",
    "                ratings.append(1)\n",
    "            elif best_label == 'Negative':\n",
    "                ratings.append(-1)\n",
    "            else:\n",
    "                ratings.append(0)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing text: {e}\")\n",
    "            ratings.append(0)\n",
    "    return ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = review_df_sementic.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(20661)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.loc[:, \"rating_semantic_generated\"] = get_rating_semantic_batch(sample[\"reviews.text\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.title</th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>reviews.rating</th>\n",
       "      <th>rating_semantic</th>\n",
       "      <th>rating_semantic_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62581</th>\n",
       "      <td>nice tablet for the price!</td>\n",
       "      <td>I purchased this for my wife so that she has a...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39270</th>\n",
       "      <td>Good for the money</td>\n",
       "      <td>Batteries for my MP3 player it takes one I sle...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38276</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>What can I say battery's</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>Outstanding speed</td>\n",
       "      <td>I bought this as a gift and the recipient love...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34706</th>\n",
       "      <td>2-year Review</td>\n",
       "      <td>I buy AAA and AA batteries about 4 - 6 times a...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64986</th>\n",
       "      <td>Tablet</td>\n",
       "      <td>This is a first for an adult. Price is right, ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28830</th>\n",
       "      <td>Very good tablet</td>\n",
       "      <td>My sister told me about the Kindle Fire and I ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21747</th>\n",
       "      <td>The 7\" Amazon Kindle Fire is the best starter ...</td>\n",
       "      <td>The 7\" Amazon Kindle Fire is the best starter ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13308</th>\n",
       "      <td>Good for what I need it for</td>\n",
       "      <td>Wanted something to take with me. (I don't use...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36059</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Batteries are batteries.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58722</th>\n",
       "      <td>Perfect gift</td>\n",
       "      <td>My children loved their previous kindles so mu...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25091</th>\n",
       "      <td>What more is there to say \"Alea\"</td>\n",
       "      <td>Alea echo is hands down the best smart device ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9534</th>\n",
       "      <td>Kindle fire</td>\n",
       "      <td>We bought this for a handicapped friend. He is...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34692</th>\n",
       "      <td>... to say about batteries except they work fo...</td>\n",
       "      <td>Not much to say about batteries except they wo...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35738</th>\n",
       "      <td>Excellent</td>\n",
       "      <td>The price is unbeatable! Never buying batterie...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8647</th>\n",
       "      <td>Amazing for the price</td>\n",
       "      <td>This tablet is great. Not the best, but it was...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51939</th>\n",
       "      <td>Replacement for non-working \"old\" Kindle</td>\n",
       "      <td>Have not had time to REALLY use it, but hope t...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10296</th>\n",
       "      <td>Nice tablet</td>\n",
       "      <td>I purchased this item as a gift for Christmas....</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12474</th>\n",
       "      <td>Great for kids</td>\n",
       "      <td>Got one for each of my kids. They use it to pl...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52521</th>\n",
       "      <td>2nd purchase</td>\n",
       "      <td>First bought the Fire HD 8\" for myself and lik...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44270</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>i dont see any reason i should be purchasing e...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49775</th>\n",
       "      <td>Great for my grandkids</td>\n",
       "      <td>My grandkids love it. They use it at home and ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43135</th>\n",
       "      <td>AmazonBasics AAA or Duracell CopperTop AAA: ca...</td>\n",
       "      <td>I tested the lifespan of these batteries with ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5150</th>\n",
       "      <td>Great.</td>\n",
       "      <td>Good purchase for a 10 year old to encourage r...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41673</th>\n",
       "      <td>Seemed like a good</td>\n",
       "      <td>batteries are batteries. Seemed like a good price</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6300</th>\n",
       "      <td>not bad for the pirce</td>\n",
       "      <td>Bought it for the price and my mother-in-law h...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66705</th>\n",
       "      <td>Great tablet</td>\n",
       "      <td>We own an ipad,samsug tablets and we have both...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17161</th>\n",
       "      <td>Love it for my toddler</td>\n",
       "      <td>The kindle fire kid is easy enough that our 2 ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17814</th>\n",
       "      <td>Excellent screen , battery life and books</td>\n",
       "      <td>I was using Nook glow light, migrating to pape...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55355</th>\n",
       "      <td>Nice tablet for the price</td>\n",
       "      <td>It's a nice tablet for the price and I use it ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20678</th>\n",
       "      <td>Best reader yet!!</td>\n",
       "      <td>I have owned exactlo, nooks, kobo's and kindle...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14241</th>\n",
       "      <td>Good tablet for price</td>\n",
       "      <td>I gave this to my 3 yr old to play games and w...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39039</th>\n",
       "      <td>Good bargain</td>\n",
       "      <td>Always looking for AA batteries, controllers f...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56690</th>\n",
       "      <td>Great Bluetooth device for audible books</td>\n",
       "      <td>I needed a device to listen to books on a long...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13071</th>\n",
       "      <td>Great tablet</td>\n",
       "      <td>I love this new tablet because it has expandab...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41824</th>\n",
       "      <td>Still checking the life</td>\n",
       "      <td>So far so good!, I put dates on these batterie...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67687</th>\n",
       "      <td>I love my Voyage!</td>\n",
       "      <td>I gave my Paperwhite to a friend and bought th...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62236</th>\n",
       "      <td>iPod nano</td>\n",
       "      <td>I had a very small nano and needed to have mor...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22243</th>\n",
       "      <td>Great product</td>\n",
       "      <td>Replacing my son's 5 year old computer. He lov...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42795</th>\n",
       "      <td>work well</td>\n",
       "      <td>Batteries 1.5 volts supply current what else c...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9819</th>\n",
       "      <td>Excellent Price</td>\n",
       "      <td>This is an excellent price for the Amazon Fire...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58137</th>\n",
       "      <td>Great kids tablet</td>\n",
       "      <td>Purchased one for my older son last year....Go...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3089</th>\n",
       "      <td>Charger</td>\n",
       "      <td>It's okay so far.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38880</th>\n",
       "      <td>Four Stars</td>\n",
       "      <td>They are batteries. They work.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50225</th>\n",
       "      <td>Great Reader</td>\n",
       "      <td>This is our 2nd one, my wife was using my most...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9600</th>\n",
       "      <td>A great Floor Cleaner.</td>\n",
       "      <td>It washer, it vacuums and it dries the floor i...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38771</th>\n",
       "      <td>Four Stars</td>\n",
       "      <td>Just fine - good value</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52403</th>\n",
       "      <td>I love my Voyage!</td>\n",
       "      <td>I gave my Paperwhite to a friend and bought th...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35640</th>\n",
       "      <td>doesn't work with wireless mouse</td>\n",
       "      <td>It doesn't work with my Amazon wireless mouse</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54698</th>\n",
       "      <td>Great for travel</td>\n",
       "      <td>Perfect travel compainion for long trips. Can ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37541</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Last longer than name brands.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12991</th>\n",
       "      <td>Good deal tablet</td>\n",
       "      <td>I bought this because my iPad 4th gen gave up ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25540</th>\n",
       "      <td>Interesting product.</td>\n",
       "      <td>Once you learn how to use it you can have some...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reviews.title  \\\n",
       "62581                         nice tablet for the price!   \n",
       "39270                                 Good for the money   \n",
       "38276                                         Five Stars   \n",
       "2408                                   Outstanding speed   \n",
       "34706                                      2-year Review   \n",
       "64986                                             Tablet   \n",
       "28830                                   Very good tablet   \n",
       "21747  The 7\" Amazon Kindle Fire is the best starter ...   \n",
       "13308                        Good for what I need it for   \n",
       "36059                                         Five Stars   \n",
       "58722                                       Perfect gift   \n",
       "25091                   What more is there to say \"Alea\"   \n",
       "9534                                         Kindle fire   \n",
       "34692  ... to say about batteries except they work fo...   \n",
       "35738                                          Excellent   \n",
       "8647                               Amazing for the price   \n",
       "51939           Replacement for non-working \"old\" Kindle   \n",
       "10296                                        Nice tablet   \n",
       "12474                                     Great for kids   \n",
       "52521                                       2nd purchase   \n",
       "44270                                         Five Stars   \n",
       "49775                             Great for my grandkids   \n",
       "43135  AmazonBasics AAA or Duracell CopperTop AAA: ca...   \n",
       "5150                                              Great.   \n",
       "41673                                 Seemed like a good   \n",
       "6300                               not bad for the pirce   \n",
       "66705                                       Great tablet   \n",
       "17161                             Love it for my toddler   \n",
       "17814          Excellent screen , battery life and books   \n",
       "55355                          Nice tablet for the price   \n",
       "20678                                  Best reader yet!!   \n",
       "14241                              Good tablet for price   \n",
       "39039                                       Good bargain   \n",
       "56690           Great Bluetooth device for audible books   \n",
       "13071                                       Great tablet   \n",
       "41824                            Still checking the life   \n",
       "67687                                  I love my Voyage!   \n",
       "62236                                          iPod nano   \n",
       "22243                                      Great product   \n",
       "42795                                          work well   \n",
       "9819                                     Excellent Price   \n",
       "58137                                  Great kids tablet   \n",
       "3089                                             Charger   \n",
       "38880                                         Four Stars   \n",
       "50225                                       Great Reader   \n",
       "9600                              A great Floor Cleaner.   \n",
       "38771                                         Four Stars   \n",
       "52403                                  I love my Voyage!   \n",
       "35640                   doesn't work with wireless mouse   \n",
       "54698                                   Great for travel   \n",
       "37541                                         Five Stars   \n",
       "12991                                   Good deal tablet   \n",
       "25540                               Interesting product.   \n",
       "\n",
       "                                            reviews.text  reviews.rating  \\\n",
       "62581  I purchased this for my wife so that she has a...             5.0   \n",
       "39270  Batteries for my MP3 player it takes one I sle...             4.0   \n",
       "38276                           What can I say battery's             5.0   \n",
       "2408   I bought this as a gift and the recipient love...             5.0   \n",
       "34706  I buy AAA and AA batteries about 4 - 6 times a...             5.0   \n",
       "64986  This is a first for an adult. Price is right, ...             5.0   \n",
       "28830  My sister told me about the Kindle Fire and I ...             5.0   \n",
       "21747  The 7\" Amazon Kindle Fire is the best starter ...             5.0   \n",
       "13308  Wanted something to take with me. (I don't use...             4.0   \n",
       "36059                           Batteries are batteries.             5.0   \n",
       "58722  My children loved their previous kindles so mu...             5.0   \n",
       "25091  Alea echo is hands down the best smart device ...             5.0   \n",
       "9534   We bought this for a handicapped friend. He is...             5.0   \n",
       "34692  Not much to say about batteries except they wo...             5.0   \n",
       "35738  The price is unbeatable! Never buying batterie...             5.0   \n",
       "8647   This tablet is great. Not the best, but it was...             4.0   \n",
       "51939  Have not had time to REALLY use it, but hope t...             5.0   \n",
       "10296  I purchased this item as a gift for Christmas....             4.0   \n",
       "12474  Got one for each of my kids. They use it to pl...             4.0   \n",
       "52521  First bought the Fire HD 8\" for myself and lik...             5.0   \n",
       "44270  i dont see any reason i should be purchasing e...             5.0   \n",
       "49775  My grandkids love it. They use it at home and ...             5.0   \n",
       "43135  I tested the lifespan of these batteries with ...             5.0   \n",
       "5150   Good purchase for a 10 year old to encourage r...             4.0   \n",
       "41673  batteries are batteries. Seemed like a good price             5.0   \n",
       "6300   Bought it for the price and my mother-in-law h...             4.0   \n",
       "66705  We own an ipad,samsug tablets and we have both...             5.0   \n",
       "17161  The kindle fire kid is easy enough that our 2 ...             5.0   \n",
       "17814  I was using Nook glow light, migrating to pape...             5.0   \n",
       "55355  It's a nice tablet for the price and I use it ...             4.0   \n",
       "20678  I have owned exactlo, nooks, kobo's and kindle...             5.0   \n",
       "14241  I gave this to my 3 yr old to play games and w...             4.0   \n",
       "39039  Always looking for AA batteries, controllers f...             5.0   \n",
       "56690  I needed a device to listen to books on a long...             5.0   \n",
       "13071  I love this new tablet because it has expandab...             5.0   \n",
       "41824  So far so good!, I put dates on these batterie...             5.0   \n",
       "67687  I gave my Paperwhite to a friend and bought th...             5.0   \n",
       "62236  I had a very small nano and needed to have mor...             4.0   \n",
       "22243  Replacing my son's 5 year old computer. He lov...             5.0   \n",
       "42795  Batteries 1.5 volts supply current what else c...             4.0   \n",
       "9819   This is an excellent price for the Amazon Fire...             5.0   \n",
       "58137  Purchased one for my older son last year....Go...             4.0   \n",
       "3089                                   It's okay so far.             4.0   \n",
       "38880                     They are batteries. They work.             4.0   \n",
       "50225  This is our 2nd one, my wife was using my most...             5.0   \n",
       "9600   It washer, it vacuums and it dries the floor i...             5.0   \n",
       "38771                             Just fine - good value             4.0   \n",
       "52403  I gave my Paperwhite to a friend and bought th...             5.0   \n",
       "35640      It doesn't work with my Amazon wireless mouse             2.0   \n",
       "54698  Perfect travel compainion for long trips. Can ...             5.0   \n",
       "37541                      Last longer than name brands.             5.0   \n",
       "12991  I bought this because my iPad 4th gen gave up ...             4.0   \n",
       "25540  Once you learn how to use it you can have some...             4.0   \n",
       "\n",
       "       rating_semantic  rating_semantic_generated  \n",
       "62581                1                          0  \n",
       "39270                1                          0  \n",
       "38276                1                          0  \n",
       "2408                 1                          0  \n",
       "34706                1                          0  \n",
       "64986                1                          0  \n",
       "28830                1                          0  \n",
       "21747                1                          0  \n",
       "13308                1                          0  \n",
       "36059                1                          0  \n",
       "58722                1                          0  \n",
       "25091                1                          0  \n",
       "9534                 1                          0  \n",
       "34692                1                          0  \n",
       "35738                1                          0  \n",
       "8647                 1                          0  \n",
       "51939                1                          0  \n",
       "10296                1                          0  \n",
       "12474                1                          0  \n",
       "52521                1                          0  \n",
       "44270                1                          0  \n",
       "49775                1                          0  \n",
       "43135                1                          0  \n",
       "5150                 1                          0  \n",
       "41673                1                          0  \n",
       "6300                 1                          0  \n",
       "66705                1                          0  \n",
       "17161                1                          0  \n",
       "17814                1                          0  \n",
       "55355                1                          0  \n",
       "20678                1                          0  \n",
       "14241                1                          0  \n",
       "39039                1                          0  \n",
       "56690                1                          0  \n",
       "13071                1                          0  \n",
       "41824                1                          0  \n",
       "67687                1                          0  \n",
       "62236                1                          0  \n",
       "22243                1                          0  \n",
       "42795                1                          0  \n",
       "9819                 1                          0  \n",
       "58137                1                          0  \n",
       "3089                 1                          0  \n",
       "38880                1                          0  \n",
       "50225                1                          0  \n",
       "9600                 1                          0  \n",
       "38771                1                          0  \n",
       "52403                1                          0  \n",
       "35640               -1                          0  \n",
       "54698                1                          0  \n",
       "37541                1                          0  \n",
       "12991                1                          0  \n",
       "25540                1                          0  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.loc[sample['rating_semantic_generated'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.883)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = (sample[\"rating_semantic_generated\"] == sample[\"rating_semantic\"]).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67992, 13)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.isnull().sum()\n",
    "combined_df.drop(columns=[\"reviews.numHelpful\", \"reviews.id\", \"name\", \"reviews.doRecommend\"], inplace=True)\n",
    "combined_df.dropna()\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.duplicated().sum()\n",
    "combined_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"../reviews/combined_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aspect generation for each product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AVphgVaX1cnluZ0-DR74', 'AVpgNzjwLJeJML43Kpxn', 'AVpfl8cLLJeJML43AE3S',\n",
       "       'AV1YE_muvKc47QAVgpwE', 'AVpe7xlELJeJML43ypLz'],\n",
       "      dtype='object', name='id')"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_reviewed = combined_df[\"id\"].value_counts()[:5].index\n",
    "top_5_reviewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-21 15:15:32] (2.0.27) ********** \u001b[32mAvailable ATEPC model checkpoints for Version:2.0.27 (this version)\u001b[0m **********\n",
      "[2025-06-21 15:15:32] (2.0.27) ********** \u001b[32mAvailable ATEPC model checkpoints for Version:2.0.27 (this version)\u001b[0m **********\n",
      "[2025-06-21 15:15:32] (2.0.27) \u001b[32mDownloading checkpoint:english \u001b[0m\n",
      "[2025-06-21 15:15:32] (2.0.27) \u001b[31mNotice: The pretrained model are used for testing, it is recommended to train the model on your own custom datasets\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading checkpoint:  16%|█▌        | 90/578 [00:53<04:50,  1.68MB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      9\u001b[39m product_id = \u001b[33m\"\u001b[39m\u001b[33mAVphgVaX1cnluZ0-DR74\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# STEP 2: Load reviews using pandas\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# df = pd.read_csv(\"..\\\\reviews\\\\combined_reviews.csv\")  # replace with your CSV path\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# product_reviews = df[df[\"id\"] == product_id][\"reviews.text\"].dropna().tolist()\u001b[39;00m\n\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# STEP 3: Load ATEPC aspect-based sentiment model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m aspect_extractor = \u001b[43mATEPC\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAspectExtractor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43menglish\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# You can also try \"english\"\u001b[39;49;00m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauto_device\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# uses GPU if available\u001b[39;49;00m\n\u001b[32m     19\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# STEP 4: Extract aspects and sentiment\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# extracted = aspect_extractor.extract_aspect(\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m#     inference_source=product_reviews,  # Add the missing inference_source parameter\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     73\u001b[39m \u001b[38;5;66;03m# print(\"\\n🧠 Suggestion Summary:\\n\")\u001b[39;00m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# print(response)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Hackathons\\Amazon HackOn\\Models\\venv\\Lib\\site-packages\\pyabsa\\tasks\\AspectTermExtraction\\prediction\\aspect_extractor.py:48\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, checkpoint, **kwargs)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mAspectExtractor\u001b[39;00m(InferenceModel):\n\u001b[32m     46\u001b[39m     task_code = TaskCodeOption.Aspect_Term_Extraction_and_Classification\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, checkpoint=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     49\u001b[39m         \u001b[38;5;66;03m# load from a trainer\u001b[39;00m\n\u001b[32m     50\u001b[39m         \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(checkpoint, task_code=\u001b[38;5;28mself\u001b[39m.task_code, **kwargs)\n\u001b[32m     52\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.checkpoint \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.checkpoint, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Hackathons\\Amazon HackOn\\Models\\venv\\Lib\\site-packages\\pyabsa\\framework\\prediction_class\\predictor_template.py:31\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, checkpoint, config, **kwargs)\u001b[39m\n\u001b[32m     21\u001b[39m def __init__(self, checkpoint: Union[str, object] = None, config=None, **kwargs):\n\u001b[32m     22\u001b[39m     \"\"\"\n\u001b[32m     23\u001b[39m     Initializes an instance of the InferenceModel class, used for performing inference on a trained model.\n\u001b[32m     24\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     :param kwargs: additional keyword arguments\n\u001b[32m     28\u001b[39m     \"\"\"\n\u001b[32m     29\u001b[39m     from pyabsa.framework.checkpoint_class.checkpoint_template import (\n\u001b[32m     30\u001b[39m         CheckpointManager,\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     )\n\u001b[32m     33\u001b[39m     self.cal_perplexity = kwargs.get(\"cal_perplexity\", False)\n\u001b[32m     35\u001b[39m     # parse the provided checkpoint to obtain the checkpoint path and configuration\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Hackathons\\Amazon HackOn\\Models\\venv\\Lib\\site-packages\\pyabsa\\framework\\checkpoint_class\\checkpoint_template.py:54\u001b[39m, in \u001b[36mparse_checkpoint\u001b[39m\u001b[34m(self, checkpoint, task_code)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse_checkpoint\u001b[39m(\n\u001b[32m     37\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     38\u001b[39m     checkpoint: Union[\u001b[38;5;28mstr\u001b[39m, Path] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     39\u001b[39m     task_code: \u001b[38;5;28mstr\u001b[39m = TaskCodeOption.Aspect_Polarity_Classification,\n\u001b[32m     40\u001b[39m ) -> Union[\u001b[38;5;28mstr\u001b[39m, Path]:\n\u001b[32m     41\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[33;03m    Parse a given checkpoint file path or name and returns the path of the checkpoint directory.\u001b[39;00m\n\u001b[32m     43\u001b[39m \n\u001b[32m     44\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[33;03m        checkpoint (Union[str, Path], optional): Zipped checkpoint name, checkpoint path, or checkpoint name queried from Google Drive. Defaults to None.\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[33;03m        task_code (str, optional): Task code, e.g. apc, atepc, tad, rnac_datasets, rnar, tc, etc. Defaults to TaskCodeOption.Aspect_Polarity_Classification.\u001b[39;00m\n\u001b[32m     47\u001b[39m \n\u001b[32m     48\u001b[39m \u001b[33;03m    Returns:\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[33;03m        Path: The path of the checkpoint directory.\u001b[39;00m\n\u001b[32m     50\u001b[39m \n\u001b[32m     51\u001b[39m \u001b[33;03m    Example:\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[33;03m        ```\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[33;03m        manager = CheckpointManager()\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[33;03m        checkpoint_path = manager.parse_checkpoint(\"checkpoint.zip\", \"apc\")\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[33;03m        ```\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(checkpoint, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(checkpoint, Path):\n\u001b[32m     58\u001b[39m         \u001b[38;5;66;03m# directly load checkpoint from local path\u001b[39;00m\n\u001b[32m     59\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(checkpoint):\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Hackathons\\Amazon HackOn\\Models\\venv\\Lib\\site-packages\\pyabsa\\framework\\checkpoint_class\\checkpoint_template.py:82\u001b[39m, in \u001b[36m_get_remote_checkpoint\u001b[39m\u001b[34m(self, checkpoint, task_code)\u001b[39m\n\u001b[32m     80\u001b[39m         checkpoint = os.path.dirname(checkpoint_config)\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(checkpoint, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m checkpoint.endswith(\u001b[33m\"\u001b[39m\u001b[33m.zip\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m         checkpoint = unzip_checkpoint(\n\u001b[32m     83\u001b[39m             checkpoint\n\u001b[32m     84\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(checkpoint)\n\u001b[32m     85\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m find_file(os.getcwd(), checkpoint)\n\u001b[32m     86\u001b[39m         )\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m checkpoint\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Hackathons\\Amazon HackOn\\Models\\venv\\Lib\\site-packages\\pyabsa\\framework\\checkpoint_class\\checkpoint_utils.py:155\u001b[39m, in \u001b[36mdownload_checkpoint\u001b[39m\u001b[34m(task, language, checkpoint)\u001b[39m\n\u001b[32m    130\u001b[39m \"\"\"\n\u001b[32m    131\u001b[39m Download a pretrained checkpoint for a given task and language.\n\u001b[32m    132\u001b[39m The download_checkpoint() function downloads a checkpoint from a given URL using the requests library. It saves the downloaded checkpoint to a temporary directory with a name that corresponds to the task and language. If the checkpoint has already been downloaded and saved in the temporary directory, the function simply returns the directory path.\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m \n\u001b[32m    141\u001b[39m \"\"\"\n\u001b[32m    143\u001b[39m fprint(\n\u001b[32m    144\u001b[39m     colored(\n\u001b[32m    145\u001b[39m         \"Notice: The pretrained model are used for testing, \"\n\u001b[32m   (...)\u001b[39m\u001b[32m    148\u001b[39m     )\n\u001b[32m    149\u001b[39m )\n\u001b[32m    150\u001b[39m huggingface_checkpoint_url = (\n\u001b[32m    151\u001b[39m     PyABSAMaterialHostAddress\n\u001b[32m    152\u001b[39m     + \"resolve/main/checkpoints/{}/{}/{}\".format(\n\u001b[32m    153\u001b[39m         checkpoint[\"Language\"], task.upper(), checkpoint[\"Checkpoint File\"]\n\u001b[32m    154\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m )\n\u001b[32m    157\u001b[39m tmp_dir = \"{}_{}_CHECKPOINT\".format(task.upper(), language.upper())\n\u001b[32m    158\u001b[39m dest_path = os.path.join(\"./checkpoints\", tmp_dir)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Hackathons\\Amazon HackOn\\Models\\venv\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Hackathons\\Amazon HackOn\\Models\\venv\\Lib\\site-packages\\requests\\models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Hackathons\\Amazon HackOn\\Models\\venv\\Lib\\site-packages\\urllib3\\response.py:628\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m    626\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    627\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp):\n\u001b[32m--> \u001b[39m\u001b[32m628\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m    631\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Hackathons\\Amazon HackOn\\Models\\venv\\Lib\\site-packages\\urllib3\\response.py:567\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m    564\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m--> \u001b[39m\u001b[32m567\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    569\u001b[39m         flush_decoder = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Hackathons\\Amazon HackOn\\Models\\venv\\Lib\\site-packages\\urllib3\\response.py:533\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    530\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m buffer.getvalue()\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    532\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m533\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.pyenv\\pyenv-win\\versions\\3.12.4\\Lib\\http\\client.py:479\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    478\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.pyenv\\pyenv-win\\versions\\3.12.4\\Lib\\socket.py:708\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    706\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    707\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    710\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.pyenv\\pyenv-win\\versions\\3.12.4\\Lib\\ssl.py:1252\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1250\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1251\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.pyenv\\pyenv-win\\versions\\3.12.4\\Lib\\ssl.py:1104\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyabsa import AspectTermExtraction as ATEPC\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "import os\n",
    "\n",
    "# STEP 1: Get product ID from user\n",
    "product_id = \"AVphgVaX1cnluZ0-DR74\"\n",
    "\n",
    "# STEP 2: Load reviews using pandas\n",
    "# df = pd.read_csv(\"..\\\\reviews\\\\combined_reviews.csv\")  # replace with your CSV path\n",
    "# product_reviews = df[df[\"id\"] == product_id][\"reviews.text\"].dropna().tolist()\n",
    "\n",
    "# STEP 3: Load ATEPC aspect-based sentiment model\n",
    "aspect_extractor = ATEPC.AspectExtractor(\n",
    "    checkpoint=\"english\",  # You can also try \"english\"\n",
    "    auto_device=True  # uses GPU if available\n",
    ")\n",
    "\n",
    "# STEP 4: Extract aspects and sentiment\n",
    "# extracted = aspect_extractor.extract_aspect(\n",
    "#     inference_source=product_reviews,  # Add the missing inference_source parameter\n",
    "#     examples=product_reviews,\n",
    "#     pred_sentiment=True,\n",
    "#     print_result=False\n",
    "# )\n",
    "\n",
    "# # STEP 5: Aggregate aspects by sentiment\n",
    "# from collections import defaultdict\n",
    "# aspect_summary = defaultdict(list)\n",
    "\n",
    "# for entry in extracted:\n",
    "#     for asp, sent in zip(entry['aspect'], entry['sentiment']):\n",
    "#         aspect_summary[sent].append(asp)\n",
    "\n",
    "# # Keep only top 10 unique aspects per sentiment\n",
    "# def top_aspects(aspect_list):\n",
    "#     from collections import Counter\n",
    "#     return [item for item, _ in Counter(aspect_list).most_common(10)]\n",
    "\n",
    "# positive_aspects = top_aspects(aspect_summary[\"Positive\"])\n",
    "# negative_aspects = top_aspects(aspect_summary[\"Negative\"])\n",
    "\n",
    "# # STEP 6: Use LangChain + Groq to give suggestions\n",
    "# os.environ[\"GROQ_API_KEY\"] = \"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\"  # Replace with your Groq key\n",
    "\n",
    "# llm = ChatGroq(model=\"llama3-70b-8192\")\n",
    "\n",
    "# prompt = PromptTemplate(\n",
    "#     input_variables=[\"positives\", \"negatives\"],\n",
    "#     template=\"\"\"\n",
    "# You are a product advisor. Based on these positive and negative aspects from product reviews:\n",
    "\n",
    "# Positive aspects: {positives}\n",
    "# Negative aspects: {negatives}\n",
    "\n",
    "# Give sellers two lists:\n",
    "# 1. Improvements they should make (based on negative aspects).\n",
    "# 2. Strengths they should highlight (based on positive aspects).\n",
    "\n",
    "# Return the output as a Python dictionary with keys 'positive' and 'negative', each having list of strings as suggestions.\n",
    "# \"\"\"\n",
    "# )\n",
    "\n",
    "# chain =  prompt | llm\n",
    "# response = chain.invoke({\n",
    "#     \"positives\": \", \".join(positive_aspects),\n",
    "#     \"negatives\": \", \".join(negative_aspects)\n",
    "# })\n",
    "\n",
    "# # Final Output\n",
    "# print(\"\\n🧠 Suggestion Summary:\\n\")\n",
    "# print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
